{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Target Folder : subject_id/synth\n",
    "#### csv : gaze_x, gaze_y, gaze_z, rotation_x, rotation_y, rotation_z, translation_x, translation_y, translation_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 데이터 제외하여 파일 또는 폴더 경로의 목록 반환 함수\n",
    "def get_filepath_list(path):\n",
    "    tmp_list = os.listdir(path)\n",
    "    real_list = []\n",
    "    for i in range(len(tmp_list)):\n",
    "        ut = tmp_list[i]\n",
    "        if ut[0] != \".\": # 임시파일 예제 : .00000.bmp\n",
    "            real_list.append(os.path.join(path,ut))\n",
    "    return real_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/T7/DKU/GazeEstimation/dataset/UTMultiview/s00-09', '/Volumes/T7/DKU/GazeEstimation/dataset/UTMultiview/s10-19', '/Volumes/T7/DKU/GazeEstimation/dataset/UTMultiview/s20-29', '/Volumes/T7/DKU/GazeEstimation/dataset/UTMultiview/s30-39', '/Volumes/T7/DKU/GazeEstimation/dataset/UTMultiview/s40-49']\n"
     ]
    }
   ],
   "source": [
    "# Dataset Root Path\n",
    "ut_path = \"./UTMultiview\"\n",
    "\n",
    "# Subject Group Path List\n",
    "ut_list = get_filepath_list(ut_path)\n",
    "\n",
    "# UT Multi View Data 폴더에서 각 Subject의 그룹 별 폴도 목록 출력\n",
    "print(ut_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pose(vector: np.ndarray) -> np.ndarray:\n",
    "    rot = cv2.Rodrigues(np.array(vector).astype(np.float32))[0]\n",
    "    vec = rot[:, 2]\n",
    "    pitch = np.arcsin(vec[1])\n",
    "    yaw = np.arctan2(vec[0], vec[2])\n",
    "    return np.array([pitch, yaw]).astype(np.float32)\n",
    "\n",
    "\n",
    "def convert_gaze(vector: np.ndarray) -> np.ndarray:\n",
    "    x, y, z = vector\n",
    "    pitch = np.arcsin(-y)\n",
    "    yaw = np.arctan2(-x, -z)\n",
    "    return np.array([pitch, yaw]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(path, zip_list):\n",
    "    # zip 파일 압축 해제 및 경로 리스트에 저장\n",
    "    unzip_list = []\n",
    "    for z_idx in range(len(zip_list)):\n",
    "        zip_file = zip_list[z_idx]\n",
    "        if zip_file[0] != \".\":\n",
    "            zip_nm = zip_file.replace(\"\\\\\",\"/\").split(\"/\")[-1].split(\".\")[0]\n",
    "            unzip_path = os.path.join(path, zip_nm)\n",
    "            if os.path.isdir(unzip_path) != True:\n",
    "                zip = zipfile.ZipFile(zip_file)\n",
    "                zip.extractall(path=unzip_path)\n",
    "            \n",
    "            unzip_list.append(unzip_path)\n",
    "    return unzip_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd70ae813bd4053a8c83e3ec5c64e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터프레임으로 구성하고자 하는 데이터의 리스트\n",
    "datas = []\n",
    "\n",
    "# Subject Group for문\n",
    "for g_idx in tqdm(range(len(ut_list))):\n",
    "    group_path = ut_list[g_idx] # Subject Group Path\n",
    "\n",
    "    # Subject ID별 데이터 관리\n",
    "    sj_list = get_filepath_list(group_path)\n",
    "    for s_idx in range(len(sj_list)):\n",
    "        subject_path = sj_list[s_idx] # Subject ID별 경로\n",
    "        synth_path = os.path.join(subject_path, \"synth\") # 사용할 데이터 폴더\n",
    "        # test_path = os.path.join(subject_path, \"test\") # 사용할 데이터 폴더\n",
    "        \n",
    "        csv_list = sorted(glob(os.path.join(synth_path, \"*.csv\"))) # csv 파일 리스트\n",
    "        zip_list = sorted(glob(os.path.join(synth_path, \"*.zip\"))) # zip 파일 리스트\n",
    "        \n",
    "        # zip 파일 압축 해제 및 경로 리스트에 저장\n",
    "        unzip_list = unzip_file(synth_path, zip_list)\n",
    "\n",
    "        # 압축이 해제 되어진 폴더 경로\n",
    "        for u_idx in range(len(unzip_list)):\n",
    "            unzip = unzip_list[u_idx].replace(\"\\\\\",\"/\")\n",
    "            \n",
    "            group_id = unzip.split(\"/\")[-4]\n",
    "            subject_id = unzip.split(\"/\")[-3] # Subject ID (s00, s01, ..., n)\n",
    "            seq_id = unzip.split(\"/\")[-1].split(\"_\")[0] # Sequence Number(0000, 0001, ... , n)\n",
    "            loc_id = unzip.split(\"/\")[-1].split(\"_\")[1] # Eye Location(Left or Right)\n",
    "            \n",
    "            img_list = get_filepath_list(unzip) # Image File List\n",
    "            pose_file = synth_path = os.path.join(ut_path, group_id, subject_id, \"raw\", \"img\"+str(seq_id), \"headpose.txt\")  # 사용할 데이터 폴더\n",
    "            with open(pose_file, 'r') as file:\n",
    "                data = file.read()\n",
    "            # 데이터에서 HeadPose 부분 찾기\n",
    "            start = data.find(\"HeadPose\")\n",
    "            end = data.find(\"Features\")\n",
    "\n",
    "            # HeadPose 부분 추출\n",
    "            headpose_data = data[start:end]\n",
    "            headpose_lines = headpose_data.split('\\n')\n",
    "            \n",
    "            translation_line = headpose_lines[1].strip('[] ')  # 대괄호 및 공백 제거\n",
    "            translation = [float(x) for x in translation_line.split()]\n",
    "            translation_vector = np.array(translation)\n",
    "            \n",
    "            rotation_data = []\n",
    "            for l_idx in range(2,5):\n",
    "                rotation_line = headpose_lines[l_idx].strip('[] ')\n",
    "                rotation = [float(x) for x in rotation_line.split()]\n",
    "                rotation_data.append(rotation)\n",
    "            rotation_matrix = np.array(rotation_data)\n",
    "            \n",
    "            # 트랜스레이션 벡터를 3D 위치 벡터로 변환\n",
    "            head_position = -translation_vector  # 위치 벡터는 -트랜스레이션 벡터\n",
    "\n",
    "            # 회전 행렬을 사용하여 방향 벡터 계산\n",
    "            direction_vector = np.array([0, 0, 1])  # 초기 방향 벡터 (예를 들어, 머리가 z-축 방향을 향할 때)\n",
    "\n",
    "            # 회전 행렬을 방향 벡터에 적용\n",
    "            direction_vector = np.array(direction_vector, dtype=float)\n",
    "            direction_vector_rotated = np.dot(rotation_matrix, direction_vector)\n",
    "\n",
    "            # 위치 벡터와 방향 벡터를 더하여 유닛 벡터 계산\n",
    "            head_direction = direction_vector_rotated + head_position\n",
    "\n",
    "            # 유닛 벡터로 정규화\n",
    "            head_unit_vector = head_direction / np.linalg.norm(head_direction)\n",
    "\n",
    "            pose_x, pose_y, pose_z = map(float, head_unit_vector)\n",
    "            pose_data = [pose_x,pose_y,pose_z]\n",
    "            if loc_id == \"left\":\n",
    "                pose = convert_pose(pose_data)\n",
    "            else:\n",
    "                pose = convert_pose(pose_data) * np.array([1, -1])\n",
    "                    \n",
    "            # Gaze CSV Data\n",
    "            columns = [\"gaze_x\", \"gaze_y\", \"gaze_z\"]\n",
    "            gaze_data = pd.read_csv(csv_list[u_idx], header=None).iloc[:,:3] # 0~8의 컬럼만 필요하기 때문에 마지막의 None 값의 컬럼은 제외\n",
    "            gaze_data.columns = columns\n",
    "            try:\n",
    "                # gaze data의 행에 해당하는 이미지 호출하여 데이터프레임 구성\n",
    "                for g_idx in range(len(gaze_data)):\n",
    "                    img_path = img_list[g_idx]\n",
    "                    image = cv2.imread(img_path)\n",
    "                    image_array = np.array(image)\n",
    "                    image_data_gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "                    \n",
    "                    gaze_data = [pose_x,pose_y,pose_z]\n",
    "                    \n",
    "                    if loc_id == \"left\":\n",
    "                        gaze = convert_gaze(gaze_data)\n",
    "                        image = image_data_gray\n",
    "                    else:\n",
    "                        image = image_data_gray[:, ::-1]\n",
    "                        gaze = convert_gaze(gaze_data) * np.array([1, -1])\n",
    "                        \n",
    "                    data_list = [subject_id, seq_id, loc_id, image.ravel(), pose[0], pose[1], gaze[0], gaze[1]]\n",
    "                    datas.append(data_list)\n",
    "            except:\n",
    "                print(f\"ZIP ERROR : {subject_id} / {seq_id} / {loc_id}\\n\")\n",
    "\n",
    "# 리스트에 담아두었던 정보들을 DataFrame으로 생성\n",
    "data_df = pd.DataFrame(columns=[\"participant_id\",\"day\",\"eye_location\",\"image\",\"head_pitch\",\"head_yaw\",\"gaze_pitch\",\"gaze_yaw\"], data=datas)\n",
    "data_df.head(3)\n",
    "data_df = data_df.sort_values(by=['participant_id', 'day']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./utm_dataset\"\n",
    "if os.path.isdir(save_path) == False:\n",
    "    os.makedirs(save_path)\n",
    "save_file = os.path.join(save_path, \"utm_synth_dataset.parquet\")\n",
    "data_df.to_parquet(save_file, engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f864393ebf2d471c8c8a075fe5a038b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 참가자별 저장\n",
    "participant_list = sorted(list(set(list(data_df['participant_id'].values))))\n",
    "os.makedirs(\"./utm_dataset/subject_synth\")\n",
    "for par_id in tqdm(participant_list):\n",
    "    par_df = data_df[data_df['participant_id'] == par_id]\n",
    "    save_path = os.path.join(\"./utm_dataset/subject_synth\", f'utm_synth_dataset_{par_id}.parquet')\n",
    "    par_df.to_parquet(save_path, engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 참가자의 위치와 이미지의 순서 별로 1500장씩 추출\n",
    "desired_sequence_count = 1500\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for participant_id in sorted(data_df['participant_id'].unique()):\n",
    "    for eye_location in data_df['eye_location'].unique():\n",
    "        subset = data_df[(data_df['participant_id'] == participant_id) & (data_df['eye_location'] == eye_location)]\n",
    "        \n",
    "        if len(subset) >= desired_sequence_count:\n",
    "            sampled_subset = subset.sample(desired_sequence_count)\n",
    "        else:\n",
    "            sampled_subset = subset.sample(desired_sequence_count, replace=True)\n",
    "        \n",
    "        result_df = pd.concat([result_df, sampled_subset])\n",
    "result_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./utm_dataset\"\n",
    "if os.path.isdir(save_path) == False:\n",
    "    os.makedirs(save_path)\n",
    "save_file = os.path.join(save_path, \"sampled_utm_synth_dataset.parquet\")\n",
    "result_df.to_parquet(save_file, engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feefa546a8a4f74b16e4979b4adda9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 참가자별 저장\n",
    "# 참가자별 저장\n",
    "participant_list = sorted(list(set(list(result_df['participant_id'].values))))\n",
    "os.makedirs(\"./utm_dataset/sampled_subject_synth\")\n",
    "for par_id in tqdm(participant_list):\n",
    "    par_df = result_df[result_df['participant_id'] == par_id]\n",
    "    save_path = os.path.join(\"./utm_dataset/sampled_subject_synth\", f'sampled_utm_synth_dataset_{par_id}.parquet')\n",
    "    par_df.to_parquet(save_path, engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
